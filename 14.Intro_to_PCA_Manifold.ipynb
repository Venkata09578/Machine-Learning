{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of intro_to_PCA_Manifold.ipynb","version":"0.3.2","provenance":[{"file_id":"1rE-7NniRftCRrGTFXUX6pqqE-BRsjpJO","timestamp":1556846809103}],"collapsed_sections":["z4AnSP-DrLFr","kZg1jyY5rLFs","snFkXeKSrLFw","w99a2X7CrLF3","L2rXBWfBrLF7","-7KunpfArLHT"]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.4"},"kernelspec":{"display_name":"Python [conda env:tensorflow]","language":"python","name":"conda-env-tensorflow-py"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yg67lQ66rLFZ","slideshow":{"slide_type":"slide"}},"source":["## Principal Component Analysis (PCA)\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wIWvVEuJrLFb","slideshow":{"slide_type":"slide"}},"source":["### Learning Objectives\n","\n","- Describe what PCA does and what it is used for in data science.\n","- Practice computing PCA with sklearn.\n","- Interpret PCA results graphically."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DAVXuaHTrLFb","slideshow":{"slide_type":"slide"}},"source":["### Lesson Guide\n","- [Motivation](#motivation)\n","- [What is PCA?](#whatispca)\n","    - [Eigenvalues and Eigenvectors](#eigenpairs)\n","    - [Principal Components](#pcs)\n","- [Manual PCA Codealong](#manual-codealong)\n","    - [1. Basic EDA](#basic-eda)\n","    - [2. Subset and Normalize](#subset)\n","    - [3. Find the Correlation Matrix](#corr)\n","    - [4. Eignenvalues and Eigenvectors](#eigen)\n","    - [5. Explained Variance](#var)\n","    - [6. Projection Matrix W](#projection)\n","    - [7. Transformed Matrix Z](#transformed)\n","- [More Reading](#more-reading)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GLaIDetsrLFc"},"source":["# PCA = Principle Component Analysis\n","\n","**Goals**: \n","\n","- *Transform* original variable/features into new, \"high-performance\" features\n","- *Reduce* the dimensionality of the data\n","- *Eliminate* multicollinearity\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iEKvRtZfrLFl","slideshow":{"slide_type":"slide"}},"source":["<a id=\"motivation\"></a>\n","## Motivation\n","\n","### Dimensionality Reduction\n","\n","Dimensionality reduction reduces the number of random variables that you are considering for analysis until you are left with the most important variables.\n","\n","> Dimensionality reduction is not an end goal in itself, but a tool to form a dataset with more parsimonious features for further visualization and/or modelling.\n","\n","### Reducing Colinearity in Input\n","\n","To get a quick summary of our data, we can calculate a covariance matrix, an unstandardized correlation matrix.\n","\n","The diagonal elements in a covariance matrix show us the variance of each of our features.\n","\n","The off-diagnal elements show the covariance, the amount of colinearity and redundancy between our variables."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IVTWZYRArLFl"},"source":["## Motivating Example\n","\n","Say that I want to predict **age** from *stress*, *income* and *health*.\n","\n","1. Three-dimensional data\n","2. Multicollinearity probably exists\n","\n","*PCA* will give me one or two **super-predictor** variables called *components* (hopefully).\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"t628Yiq_rLFn","slideshow":{"slide_type":"slide"}},"source":["<a id=\"whatispca\"></a>\n","## What is PCA?\n","\n","---\n","\n","PCA is the quintessential \"dimensionality reduction\" algorithm. \n","\n","_Dimensionality reduction_ is the process of combining or collapsing the existing features (columns in X) into fewer features. \n","\n","These hopefully:\n","\n","- Retain the signal in the original data, and\n","- Reduce noise."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7dLWI45orLFn","slideshow":{"slide_type":"fragment"}},"source":["---\n","\n","**Essentially...**\n","\n","- PCA finds *linear combinations* of current predictor variables that...\n","- create new \"principal components\". The principal components explain...\n","- the maximum possible amount of variance in your predictors.\n","\n","$$ PC1 = w_{1,1}(\\text{stress}) + w_{2,1}(\\text{income}) + w_{3,1}(\\text{health})$$\n","\n","$$ PC2 = w_{1,2}(\\text{stress}) + w_{2,2}(\\text{income}) + w_{3,2}(\\text{health})$$\n","\n","$$ PC3 = w_{1,3}(\\text{stress}) + w_{2,3}(\\text{income}) + w_{3,3}(\\text{health})$$\n","\n","This is cool because...\n","\n","- $PC1$ is more important than $PC2$ is better than $PC3$  \n","- All of these  $PCs$ are *uncorrelated*\n","\n","---\n","\n","**Visually...**\n","\n","> Think of PCA as a coordinate transformation.  The old axes are the original variables (columns). The new axes are the principal components from PCA.\n","\n","**The new axes (principal components) become the  most concise, informative descriptors of our data as a whole.**\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"b-6OKxairLFo","slideshow":{"slide_type":"slide"}},"source":["<img alt=\"orthogonal eigenvectors\" src=\"https://drive.google.com/uc?export=view&id=117wER1h6aWurSSjghUUNjPBqpm9xydl4\">\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3GLdaSzarLFp","slideshow":{"slide_type":"slide"}},"source":["<img alt=\"[transformed XY\" src=\"https://drive.google.com/uc?export=view&id=1UfoiTOatAFGybhf3Kg8UG21s8ijw9ufY\">"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZuFTHbXLrLFp","slideshow":{"slide_type":"slide"}},"source":["<a id=\"pcs\"></a>\n","### Principal Components\n","\n","---\n","\n","- We are looking for new *directions* in feature space\n","- Each consecutive direction tries to maximize *remaining variance*\n","- Each direction is *orthogonal* to all the others\n","\n","**These new *directions* are the \"principal components\", i.e. the new coordinate system for your data.**\n","\n","> Applying PCA to your data *transforms* your original data columns (variables) onto the new principal component axes.\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aCEhFFllrLFq"},"source":["(Did you catch that?  The *variables* define the *cordinate system*.)\n","\n","(CP1) **Let's review...**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"z4AnSP-DrLFr"},"source":["**The PCA transformation creates new variables that...**\n","1. Optimize \"explained variance\", and\n","2. Are uncorrelated.\n","\n","Creating these variables is a well-defined mathematical process. In essence, **each component is created as a weighted sum of your original columns, such that all components are orthogonal (perpendicular) to each other**.\n","\n","#### Example Continued\n","\n","The inputs `stress`, `income` and `health`...\n","\n","...can be *replaced* with 3 *new* variables...\n","\n","- `PC1` $\\rightarrow$ most variance\n","- `PC2`\n","- `PC3` $\\rightarrow$ least variance (noise?)\n","\n","---\n","\n","Mathematically:\n","\n","$$ PC1 = w_{1,1}(\\text{stress}) + w_{2,1}(\\text{income}) + w_{3,1}(\\text{health})$$\n","\n","$$ PC2 = w_{1,2}(\\text{stress}) + w_{2,2}(\\text{income}) + w_{3,2}(\\text{health})$$\n","\n","$$ PC3 = w_{1,3}(\\text{stress}) + w_{2,3}(\\text{income}) + w_{3,3}(\\text{health})$$\n","\n","The weights are called *loadings*... they are coefficients indicating how heavily each of the input data are weighted\n","\n","e.g.\n","\n","$$ PC1 = 0.01(\\text{stress}) - 0.54(\\text{income}) + 0.71(\\text{health})$$\n","\n","> We will see how to get these values from `sklearn`\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KlkHjhEKrLFr"},"source":["### Capturing variance\n","\n","The total variance of your data gets redistributed among the principal components:\n","\n","$$\\text{var}(PC1) > \\text{var}(PC2) > \\text{var}(PC3)$$\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kZg1jyY5rLFs"},"source":["> #### Interpreting PCA: Signal v. Noise\n","\n","> PCA attempts to *maximize signal* (high variance) while *isolating noise* (low variance)\n","\n","> - Most variance captured in first several principal components\n","> - Noise isolated to last several principal compoments\n","> - This done simultaneously across *all input variables*\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wNGFVj71rLFs"},"source":["### Isolating variance\n","\n","There is no covariance between principal components\n","\n","$$\\text{covar}(PC1, PC2) = 0$$\n","\n","$$\\text{covar}(PC1, PC3) = 0$$\n","\n","$$\\text{covar}(PC2, PC3) = 0$$\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KeJ7kppBrLFt"},"source":["**Two assumptions that PCA makes:**\n","1. **Linearity:** The data does not hold nonlinear relationships.\n","2. **Large variances define importance:** The dimensions are constructed to maximize remaining variance."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"m4ZPJvSkrLFt","slideshow":{"slide_type":"slide"}},"source":["**PRINCIPAL COMPONENT TRANSFORMATION OF DATA: PC1 VS PC2**\n","\n","[setosa.io has an extremely nice interactive visualization for PCA](http://setosa.io/ev/principal-component-analysis/)\n","\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WAJmXZ3NrLFv","slideshow":{"slide_type":"-"}},"source":["<img alt=\"pca_coordinate_transformation\" src=\"https://drive.google.com/uc?export=view&id=1EoJBgCaeghbJGbx7SVwtx0IIUcji07lv\">"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"snFkXeKSrLFw"},"source":["### How we derive PCA\n","PCA relies on the...\n","\n","**Eigenvalue decomposition of the covariance matrix**\n","This diagonalizes the covariance matrix, therby eliminating covariance.\n","\n","**The principal component transformation**\n","This transforms each input variable $X$ onto a new orthogonal basis in which the new variables $Z$ are maximally variant.\n","\n","$$ \\mathbf{Z = WX} $$\n","\n","> * Sigma = Covariance Matrix (X)// X is the original feature data\n","> * [U,S,V] = svd(Sigma)//Perform Singular Value Decomposition\n","> * Ureduce = U(:,1:k) // k is the number of PCA components\n","> * W = Ureduce<sup>T</sup>\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"w99a2X7CrLF3","slideshow":{"slide_type":"slide"}},"source":["### Why would we want to do PCA?\n","\n","---\n","\n","- We can **reduce the number of dimensions** (remove less important components), while losing mostly noise rather than signal.\n","- Since we are assuming our variables are interrelated (at least in the sense that they together explain a dependent variable), the information of interest should exist along directions with largest variance.\n","- The directions of largest variance should have the highest signal-to-noise ratio.\n","- Correlated predictor variables (also referred to as \"redundancy\" of information) are combined into independent variables. Our predictors from PCA are guaranteed to be independent.\n","\n","---\n","\n","[Good paper on PCA](http://arxiv.org/pdf/1404.1100.pdf)\n","\n","[Nice site on how PCA is done step by step with coding](http://sebastianraschka.com/Articles/2015_pca_in_3_steps.html#pca-vs-lda)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KYfN8Gf-rLF4","slideshow":{"slide_type":"slide"}},"source":["<a id=\"manual-codealong\"></a>\n","## PCA Codealong\n","\n","---\n","\n","**DATA**\n","\n","We are going to be using a simple 75-row, 4-column dataset with demographic information. It contains:\n","\n","    age (limited to 20-65)\n","    income\n","    health (a rating on a scale of 1-100, where 100 is the best health)\n","    stress (a rating on a scale of 1-100, where 100 is the most stressed)\n","    \n","All of the variables are continuous.\n","\n","---"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1WbzJM4cYp1I","outputId":"46535e89-7495-4e84-dc03-2930da2cbadd","executionInfo":{"status":"ok","timestamp":1556847094747,"user_tz":420,"elapsed":48526,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["#1 Code to read csv file into colaboratory:\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# 1. Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |▎                               | 10kB 15.4MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 2.8MB/s \n","\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ubjxW9IrYrMG","colab":{}},"source":["#2. Get the file\n","#make sure you upload all your data files to your Google drive and change share->Advanced->change->anyone with the link can view\n","downloaded = drive.CreateFile({'id':'1FRTKbjLnzxDp0mJ3WHaFO-hYmwfXCW-V'}) # replace the id with id of file you want to access\n","downloaded.GetContentFile('simple_demographics.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"p7c330SWrLF5","slideshow":{"slide_type":"fragment"},"outputId":"027e1856-4bef-4341-e560-e673e3b40dc3","executionInfo":{"status":"ok","timestamp":1556847096193,"user_tz":420,"elapsed":49943,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","\n","sns.set_style('white')\n","\n","demo = pd.read_csv('simple_demographics.csv')\n","demo.shape"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(75, 4)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"wOmHHbWaXLk3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":202},"outputId":"22b9ac8d-2076-4e38-f22b-49ac09f40abd","executionInfo":{"status":"ok","timestamp":1556847843069,"user_tz":420,"elapsed":390,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}}},"source":["demo.head()"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>health</th>\n","      <th>income</th>\n","      <th>stress</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>21</td>\n","      <td>74.0</td>\n","      <td>42746.0</td>\n","      <td>53.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>33</td>\n","      <td>64.0</td>\n","      <td>72792.0</td>\n","      <td>49.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>30</td>\n","      <td>78.0</td>\n","      <td>74178.0</td>\n","      <td>64.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>32</td>\n","      <td>71.0</td>\n","      <td>102548.0</td>\n","      <td>63.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>57</td>\n","      <td>46.0</td>\n","      <td>120418.0</td>\n","      <td>35.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age  health    income  stress\n","0   21    74.0   42746.0    53.0\n","1   33    64.0   72792.0    49.0\n","2   30    78.0   74178.0    64.0\n","3   32    71.0  102548.0    63.0\n","4   57    46.0  120418.0    35.0"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"L2rXBWfBrLF7","slideshow":{"slide_type":"slide"}},"source":["<a id=\"basic-eda\"></a>\n","### 1. Basic EDA\n","\n","Make a seaborn pairplot for the dataset to see how each feaure is correlated to the other.\n","\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"r8_semgurLF_","slideshow":{"slide_type":"slide"}},"source":["<a id=\"subset\"></a>\n","### 2. Subset and normalize\n","\n","Subset the data to only include:\n","\n","    income\n","    health\n","    stress\n","\n","We will be comparing the principal components to age specifically, so we are leaving age out.\n","\n","---"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5JPZNEaMrLF_","slideshow":{"slide_type":"fragment"},"colab":{}},"source":["demo_noage = demo[['health','income','stress']]\n","#Let's normalize the data\n","demo_noage = (demo_noage - demo_noage.mean()) / demo_noage.std()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Y2kLOsN5rLGC","slideshow":{"slide_type":"slide"}},"source":["<a id=\"corr\"></a>\n","### 3. Calculate correlation matrix\n","\n","We will be using the correlation matrix to calculate the eigenvectors and eigenvalues.\n","\n","---"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"09wd2jVNrLGD","outputId":"8c180036-d4b5-4dd6-a8b0-f3858fe81130","slideshow":{"slide_type":"fragment"},"executionInfo":{"status":"ok","timestamp":1556847096201,"user_tz":420,"elapsed":49920,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}},"colab":{"base_uri":"https://localhost:8080/","height":141}},"source":["demo_noage_corr = np.corrcoef(demo_noage.values.T)\n","demo_noage.corr()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>health</th>\n","      <th>income</th>\n","      <th>stress</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>health</th>\n","      <td>1.000000</td>\n","      <td>0.192037</td>\n","      <td>0.527663</td>\n","    </tr>\n","    <tr>\n","      <th>income</th>\n","      <td>0.192037</td>\n","      <td>1.000000</td>\n","      <td>-0.347925</td>\n","    </tr>\n","    <tr>\n","      <th>stress</th>\n","      <td>0.527663</td>\n","      <td>-0.347925</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          health    income    stress\n","health  1.000000  0.192037  0.527663\n","income  0.192037  1.000000 -0.347925\n","stress  0.527663 -0.347925  1.000000"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NIaBg2d7rLGF","slideshow":{"slide_type":"slide"}},"source":["<a id=\"eigen\"></a>\n","### 4. Calculate the principal components and associated explained variances\n","\n","---"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JcslVQZirLGG","outputId":"b3e17edb-8f09-46f8-bf36-a7ce080fda26","executionInfo":{"status":"ok","timestamp":1556847096588,"user_tz":420,"elapsed":50271,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["from sklearn.decomposition import PCA\n","\n","X = demo_noage\n","\n","pca = PCA()\n","pca = pca.fit(X)\n","\n","print(pca.explained_variance_)\n","print(pca.components_)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[1.55645677 1.17357375 0.26996948]\n","[[-0.6187659   0.25173885 -0.74414804]\n"," [ 0.5126449   0.84716255 -0.13968116]\n"," [-0.59525118  0.46791364  0.65324793]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VyztFwMmrLGK"},"source":["Interpreting the \"components\": recall that\n","\n","$$ PC1 = w_{1,1}(\\text{health}) + w_{2,1}(\\text{income}) + w_{3,1}(\\text{stress})$$\n","\n","$$ PC2 = w_{1,2}(\\text{health}) + w_{2,2}(\\text{income}) + w_{3,2}(\\text{stress})$$\n","\n","$$ PC3 = w_{1,3}(\\text{health}) + w_{2,3}(\\text{income}) + w_{3,3}(\\text{stress})$$\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xRTm7QQvrLGZ","slideshow":{"slide_type":"slide"}},"source":["<a id=\"transformed\"></a>\n","### 5. Construct the Transformed Data Set $Z$\n","\n","---"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"X1K7uI4VrLGa","outputId":"880b602a-a5e7-4590-d1f5-bd020fd12c5a","executionInfo":{"status":"ok","timestamp":1556847096590,"user_tz":420,"elapsed":50252,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["Z = pca.transform(demo_noage)\n","\n","features_pca = ['PC'+str(i+1) for i in range(pca.n_components_)]\n","Z = pd.DataFrame(Z, columns=features_pca)\n","Z.head(5)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PC1</th>\n","      <th>PC2</th>\n","      <th>PC3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.882350</td>\n","      <td>-0.150070</td>\n","      <td>-1.166109</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.104542</td>\n","      <td>0.102205</td>\n","      <td>-0.597921</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-1.372329</td>\n","      <td>0.496715</td>\n","      <td>-0.563529</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.867671</td>\n","      <td>0.797774</td>\n","      <td>-0.017223</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.566225</td>\n","      <td>0.491018</td>\n","      <td>0.087187</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        PC1       PC2       PC3\n","0 -0.882350 -0.150070 -1.166109\n","1 -0.104542  0.102205 -0.597921\n","2 -1.372329  0.496715 -0.563529\n","3 -0.867671  0.797774 -0.017223\n","4  1.566225  0.491018  0.087187"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"vwt7bRGD8yd0","colab_type":"code","outputId":"8ee182ab-f4ef-4534-96fe-7f090d38577a","executionInfo":{"status":"ok","timestamp":1556847096592,"user_tz":420,"elapsed":50230,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["Z.shape"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(75, 3)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"z6OHkuNsrLGd","outputId":"3b68194c-3c02-46a1-e356-df087b0430c5","executionInfo":{"status":"ok","timestamp":1556847096593,"user_tz":420,"elapsed":50207,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}},"colab":{"base_uri":"https://localhost:8080/","height":141}},"source":["Z.corr()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PC1</th>\n","      <th>PC2</th>\n","      <th>PC3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>PC1</th>\n","      <td>1.000000e+00</td>\n","      <td>7.531902e-16</td>\n","      <td>6.017637e-17</td>\n","    </tr>\n","    <tr>\n","      <th>PC2</th>\n","      <td>7.531902e-16</td>\n","      <td>1.000000e+00</td>\n","      <td>1.239421e-16</td>\n","    </tr>\n","    <tr>\n","      <th>PC3</th>\n","      <td>6.017637e-17</td>\n","      <td>1.239421e-16</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              PC1           PC2           PC3\n","PC1  1.000000e+00  7.531902e-16  6.017637e-17\n","PC2  7.531902e-16  1.000000e+00  1.239421e-16\n","PC3  6.017637e-17  1.239421e-16  1.000000e+00"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zn57smB2rLG_"},"source":["### 6. PCA applied to prediction problems"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Smh7CLsUrLHA"},"source":["Now build out a base-line linear regression model predicting `age` from `health`, `income` and `stress`."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NY9PLqZ9rLHB","outputId":"57adf65b-36dc-495b-912e-49168dd970b8","executionInfo":{"status":"ok","timestamp":1556848222585,"user_tz":420,"elapsed":385,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import cross_val_score\n","\n","features = ['health', 'income', 'stress']\n","\n","X = demo[features]\n","y = demo['age']\n","\n","ss = StandardScaler()\n","Xs = ss.fit_transform(X)\n","\n","lr = LinearRegression()\n","\n","print('Cross validataion score with Linear Regression: %.2f%%' %(cross_val_score(lr, Xs, y, cv=5).mean()*100))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Cross validataion score with Linear Regression: 85.56%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zBeex0tErLHH"},"source":["### Repeat the linear regression, but reduce the dimensionality to 2 (instead of 3) using PCA.  "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cl0tR0WArLHH","outputId":"87642085-f4d8-4c0f-a8f9-e360bec5d6cf","executionInfo":{"status":"ok","timestamp":1556847096864,"user_tz":420,"elapsed":50436,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}},"colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["from sklearn.decomposition import PCA\n","\n","X = demo[features]\n","y = demo['age']\n","\n","ss = StandardScaler()\n","Xs = ss.fit_transform(X)\n","\n","pca = PCA(n_components=2)\n","Xt = pca.fit_transform(Xs)\n","\n","lr = LinearRegression()\n","\n","print('Cross validataion score with Linear Regression and 2 PCA components: %.2f%%' %(cross_val_score(lr, Xt, y, cv=5).mean()*100))\n","\n","pd.DataFrame(pca.components_.T, columns=['PC1', 'PC2'], index=features)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Cross validataion score with Linear Regression and 2 PCA components: 72.24%\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PC1</th>\n","      <th>PC2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>health</th>\n","      <td>-0.618766</td>\n","      <td>0.512645</td>\n","    </tr>\n","    <tr>\n","      <th>income</th>\n","      <td>0.251739</td>\n","      <td>0.847163</td>\n","    </tr>\n","    <tr>\n","      <th>stress</th>\n","      <td>-0.744148</td>\n","      <td>-0.139681</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             PC1       PC2\n","health -0.618766  0.512645\n","income  0.251739  0.847163\n","stress -0.744148 -0.139681"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oaVqkTH1rLHJ","colab":{}},"source":["def pca_performance(Xs,n):\n","  \n","#write a function to try out different PCA components\n","#print out the prediction\n","  \n","  pca = PCA(n_components=n)\n","  Xt = pca.fit_transform(Xs)\n","\n","  lr = LinearRegression()\n","\n","  print('Cross validataion score with Linear Regression and %d PCA components: %.2f%%' %(n,cross_val_score(lr, Xt, y, cv=5).mean()*100))\n","\n","#   pd.DataFrame(pca.components_.T, columns=['PC1', 'PC2'], index=features)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PnV2YnKyrLHK","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"1723a29c-5527-4bf7-eb1b-7d28a5fe0574","executionInfo":{"status":"ok","timestamp":1556848915591,"user_tz":420,"elapsed":353,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}}},"source":["pca_performance(Xs,1)\n","pca_performance(Xs,2)\n","pca_performance(Xs,3)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Cross validataion score with Linear Regression and 1 PCA components: 69.92%\n","Cross validataion score with Linear Regression and 2 PCA components: 72.24%\n","Cross validataion score with Linear Regression and 3 PCA components: 85.56%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3ld9Ba4ZsVvi"},"source":["## Apply PCA to Digits Dataset"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jtof4cVosVvk","colab":{}},"source":["# starter code \n","from sklearn.datasets import load_digits\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","digits = load_digits()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pjmGr7x7r2-x","colab":{}},"source":["X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SmS_pVDfsVv9","colab":{}},"source":["# normalizing the dataset \n","ss = StandardScaler()\n","X_train = ss.fit_transform(X_train)\n","X_test = ss.transform(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XiyV3RtCpIJb","outputId":"b7431860-a783-4b31-a11f-1a4f9afabab9","colab":{"base_uri":"https://localhost:8080/","height":159},"executionInfo":{"status":"ok","timestamp":1556847140206,"user_tz":420,"elapsed":644,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}}},"source":["%%time\n","#Let's see how good is Logistic Regression\n","logit = LogisticRegression()\n","logit.fit(X_train, y_train)\n","print (\"Logistic Regression Accuracy: %.2f%%\" %(logit.score(X_test, y_test)*100))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n","  \"this warning.\", FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Logistic Regression Accuracy: 98.06%\n","CPU times: user 410 ms, sys: 1.97 ms, total: 412 ms\n","Wall time: 419 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_1BrpyD4im52","outputId":"49dc9909-591c-4d46-9f7b-8216d75cae67","colab":{"base_uri":"https://localhost:8080/","height":159},"executionInfo":{"status":"ok","timestamp":1556847141217,"user_tz":420,"elapsed":345,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}}},"source":["%%time\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components=16)\n","X_train_t = pca.fit_transform(X_train)\n","X_test_t = pca.transform(X_test)\n","logit = LogisticRegression()\n","logit.fit(X_train_t, y_train)\n","print (\"Logistic Regression Accuracy with %d PCA components: %.2f%%\" %(16,logit.score(X_test_t, y_test)*100))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Logistic Regression Accuracy with 16 PCA components: 94.17%\n","CPU times: user 135 ms, sys: 87 ms, total: 222 ms\n","Wall time: 122 ms\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n","  \"this warning.\", FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Bhq9OKambyvu","colab_type":"code","colab":{}},"source":["def digit_pca(X_train,X_test,y_train,y_test, n):\n","  pca = PCA(n_components=n)\n","  X_train_t = pca.fit_transform(X_train)\n","  X_test_t = pca.transform(X_test)\n","  logit = LogisticRegression()\n","  logit.fit(X_train_t, y_train)\n","  print (\"Logistic Regression Accuracy with %d PCA components: %.2f%%\" %(16,logit.score(X_test_t, y_test)*100))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jFqW5mJFlEVY","colab":{"base_uri":"https://localhost:8080/","height":159},"outputId":"242a38bf-a38d-41fe-e03e-014df8ba67e0","executionInfo":{"status":"ok","timestamp":1556849159243,"user_tz":420,"elapsed":704,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}}},"source":["%%time\n","digit_pca(X_train,X_test,y_train,y_test, 64)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n","  \"this warning.\", FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Logistic Regression Accuracy with 16 PCA components: 98.06%\n","CPU times: user 477 ms, sys: 76.1 ms, total: 553 ms\n","Wall time: 485 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OlQrzQnlmeHf","colab":{"base_uri":"https://localhost:8080/","height":159},"outputId":"0abc915b-8fff-4d2a-a0c8-48b136dce2f6","executionInfo":{"status":"ok","timestamp":1556849167647,"user_tz":420,"elapsed":602,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}}},"source":["%%time\n","digit_pca(X_train,X_test,y_train,y_test, 32)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n","  \"this warning.\", FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Logistic Regression Accuracy with 16 PCA components: 95.83%\n","CPU times: user 266 ms, sys: 112 ms, total: 378 ms\n","Wall time: 263 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uOEyHejsmn3k","colab":{"base_uri":"https://localhost:8080/","height":159},"outputId":"ae05bfb1-2f22-4850-9860-6e390892471c","executionInfo":{"status":"ok","timestamp":1556849168610,"user_tz":420,"elapsed":349,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}}},"source":["%%time\n","digit_pca(X_train,X_test,y_train,y_test, 16)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Logistic Regression Accuracy with 16 PCA components: 94.17%\n","CPU times: user 151 ms, sys: 83.6 ms, total: 235 ms\n","Wall time: 128 ms\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n","  \"this warning.\", FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OqIDbtozmrLU","colab":{"base_uri":"https://localhost:8080/","height":159},"outputId":"f2b42765-d23e-4d44-be04-e8f436af060f","executionInfo":{"status":"ok","timestamp":1556849170076,"user_tz":420,"elapsed":347,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}}},"source":["%%time\n","digit_pca(X_train,X_test,y_train,y_test, 8)"],"execution_count":39,"outputs":[{"output_type":"stream","text":["Logistic Regression Accuracy with 16 PCA components: 88.06%\n","CPU times: user 90.2 ms, sys: 68.3 ms, total: 158 ms\n","Wall time: 92.6 ms\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n","  \"this warning.\", FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sDfGhL-DsPyK"},"source":["## Digit recognition with Manifold Learning"]},{"cell_type":"markdown","metadata":{"id":"3GnCZuGuGzKw","colab_type":"text"},"source":["<img src=\"http://benalexkeen.com/wp-content/uploads/2017/05/isomap.png\" style=\"float: left; margin: 20px; height: 75px\">"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JH_pVQqBpYlx","colab":{}},"source":["from sklearn.manifold import Isomap\n","def digit_manifold(X_train,X_test,y_train,y_test, n):\n","  model = Isomap(n_components=n)\n","  X_train_t = model.fit_transform(X_train)\n","  X_test_t = model.transform(X_test)\n","  logit = LogisticRegression()\n","  logit.fit(X_train_t, y_train)\n","  print (\"Logistic Regression Accuracy with %d Isomap components: %.2f%%\" %(n,logit.score(X_test_t, y_test)*100))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mTkQeunDsvmQ","outputId":"870dadc5-8269-4723-d5c6-ca52ab32e546","colab":{"base_uri":"https://localhost:8080/","height":159},"executionInfo":{"status":"ok","timestamp":1556849248459,"user_tz":420,"elapsed":2908,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}}},"source":["%%time\n","digit_manifold(X_train,X_test,y_train,y_test, 64)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n","  \"this warning.\", FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Logistic Regression Accuracy with 64 Isomap components: 97.78%\n","CPU times: user 2.75 s, sys: 334 ms, total: 3.08 s\n","Wall time: 2.61 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8cKf5Yd_eVsy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":159},"outputId":"465cdd36-f0ae-4013-fff3-60b2017c67ac","executionInfo":{"status":"ok","timestamp":1556849724462,"user_tz":420,"elapsed":2456,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}}},"source":["%%time\n","digit_manifold(X_train,X_test,y_train,y_test, 32)"],"execution_count":42,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n","  \"this warning.\", FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Logistic Regression Accuracy with 32 Isomap components: 96.11%\n","CPU times: user 2.58 s, sys: 275 ms, total: 2.85 s\n","Wall time: 2.24 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ktcjuGjYeVfQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":159},"outputId":"4309f371-51bc-42f1-f5fa-c3cc9c2ea6f1","executionInfo":{"status":"ok","timestamp":1556849740912,"user_tz":420,"elapsed":2287,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}}},"source":["%%time\n","digit_manifold(X_train,X_test,y_train,y_test, 16)"],"execution_count":43,"outputs":[{"output_type":"stream","text":["Logistic Regression Accuracy with 16 Isomap components: 95.28%\n","CPU times: user 2.32 s, sys: 203 ms, total: 2.52 s\n","Wall time: 1.99 s\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n","  \"this warning.\", FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"78aJWW3xeeZI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":159},"outputId":"9e853869-4684-43fe-f1ab-b3702a410862","executionInfo":{"status":"ok","timestamp":1556849761535,"user_tz":420,"elapsed":1859,"user":{"displayName":"Prathusha Koouri","photoUrl":"","userId":"11784553990265599358"}}},"source":["%%time\n","digit_manifold(X_train,X_test,y_train,y_test, 5)"],"execution_count":44,"outputs":[{"output_type":"stream","text":["Logistic Regression Accuracy with 5 Isomap components: 91.11%\n","CPU times: user 1.59 s, sys: 111 ms, total: 1.7 s\n","Wall time: 1.54 s\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n","  \"this warning.\", FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-7KunpfArLHT","slideshow":{"slide_type":"slide"}},"source":["<a id=\"more-reading\"></a>\n","### More useful links, reading, and references for images\n","\n","---\n","\n","[PCA 4 dummies](https://georgemdallas.wordpress.com/2013/10/30/principal-component-analysis-4-dummies-eigenvectors-eigenvalues-and-dimension-reduction/)\n","\n","[Stackoverflow making sense of PCA](http://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues)\n","\n","[PCA and spectral theorem](http://stats.stackexchange.com/questions/217995/what-is-an-intuitive-explanation-for-how-pca-turns-from-a-geometric-problem-wit)\n","\n","[PCA in 3 steps: eigendecomposition and SVD](http://sebastianraschka.com/Articles/2015_pca_in_3_steps.html#pca-vs-lda)\n","\n","[Tutorial on PCA](http://arxiv.org/pdf/1404.1100.pdf)\n","\n","[PCA math and examples](http://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch18.pdf)"]}]}